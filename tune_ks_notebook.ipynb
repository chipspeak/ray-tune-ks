{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1667e41-eccd-49ae-b31a-760a6e0726d7",
   "metadata": {},
   "source": [
    "# Ray Tune Knowledge Share\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b796f-4b7c-4fee-8c5c-dfc25cbb35a0",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "* Access to a ROSA Cluster.\n",
    "* This notebook and accompanying files in your workbench's directory.\n",
    "* The CodeFlare SDK installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b0153-1137-4de0-b90a-0d23732fc230",
   "metadata": {},
   "source": [
    "## Background\n",
    "Ray Tune is a python library for experimentation execution and hyperparameter tuning at any scale. It leverages popular frameworks like PyTorch and TensorFlow and state of the art algorithms to allow a user to perform their experiments with ease.\n",
    "\n",
    "By default, Ray Tune is installed with the CodeFlare SDK. It can utilise the SDK's job submission client to perform these fine tuning tasks via KubeRay in a RHOAI instance. This notebook aims to demonstrate this using the client and a python fine tuning script.\n",
    "\n",
    "This notebook will feature a mixture of the required executable setup and accompanying snippets from the tuning script to illustrate all of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d8302d-1396-4e27-8a0a-e3b66351e34a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, we'll to import the CodeFlare SDK and relevant functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e3ed1-6003-4a27-acb2-6c6485f52fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies from codeflare-sdk\n",
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication, RayJobClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6ef6b-c229-48fa-b104-9b69da61d9e3",
   "metadata": {},
   "source": [
    "Next, we'll need to define our authorisation via our OpenShift tokens and login via `auth.login()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d7f05-f606-49da-a39f-db09ece28278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeflare_sdk import TokenAuthentication\n",
    "auth = TokenAuthentication(\n",
    "    token = \"sha256~q1VwpQtDPzY5TkjqCOlhcCsvkbpO1Bk5PgLNSN63zPc\",\n",
    "    server = \"https://api.n4e0h1y1r9l0d7z.kuuz.p3.openshiftapps.com:443\",\n",
    "    skip_tls=False\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5ab3b-78e5-4263-aebb-af54b906a7b5",
   "metadata": {},
   "source": [
    "Now we can define our Ray Cluster. This is the same Ray Cluster that we'll use for our Tune experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa12837-96b9-4901-b309-d876baa3974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name='ray-tune-ks',\n",
    "    head_cpu_requests='500m',\n",
    "    head_cpu_limits='500m',\n",
    "    head_memory_requests=2,\n",
    "    head_memory_limits=5,\n",
    "    num_workers=2,\n",
    "    worker_cpu_requests='250m',\n",
    "    worker_cpu_limits=3,\n",
    "    worker_memory_requests=4,\n",
    "    worker_memory_limits=5,\n",
    "    head_extended_resource_requests={'nvidia.com/gpu':0}, \n",
    "    worker_extended_resource_requests={'nvidia.com/gpu':0},\n",
    "    write_to_file=False, \n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12c760-b58b-49e9-bb36-a14f711bd3a9",
   "metadata": {},
   "source": [
    "We can create this using `cluster.apply()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29d3b5-fff7-46d2-a3a3-579681da90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633b585-ce64-4e51-9fae-858f4166309b",
   "metadata": {},
   "source": [
    "And then verify its status via `cluster.details()`. This may take some time to become active, once it does, click the dashboard link (we'll need it later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0c241-7521-4a80-9b66-acede6c37c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af8062-00ef-448f-9cbb-0662caf6bccf",
   "metadata": {},
   "source": [
    "Before we actually run the first job, let's break down some of its logic first and how it relates to Ray Train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e986245-def1-4c3b-81a3-5e72b12d4845",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec2033-2af8-4968-a1a2-131f8e340b2c",
   "metadata": {},
   "source": [
    "The `simple_mnist_job.py` file will serve to illustrate some simple machine learning concepts.\n",
    "\n",
    "```python\n",
    "def objective(config):\n",
    "    for step in range(10):\n",
    "        x, y = config[\"x\"], config[\"y\"]\n",
    "        loss = (x - 3) ** 2 + (y + 1) ** 2 + random.random() * 0.1\n",
    "        session.report({\"loss\": loss})\n",
    "```\n",
    "\n",
    "* It defines a simple function named `objective()` which takes the `config` dictionary from Ray Train. This is a dict that contains various hyperparameters. \n",
    "* To simulate iterating through epochs we'll loop through 10 iterations.\n",
    "* We'll define the loss via a quadtratic equation with some randomness.\n",
    "* Then we'll output the loss results via Ray Tune. \n",
    "\n",
    "This essentially acts as a 'faked' training loop to demonstrate Ray Tune. It doesn't actually fine tune anything, simply demonstrates the process. The below snippet is where our function is passed to Ray Tune.\n",
    "\n",
    "```python\n",
    "tune.run(\n",
    "    objective,\n",
    "    config={\n",
    "        \"x\": tune.uniform(-10, 10),\n",
    "        \"y\": tune.uniform(-10, 10),\n",
    "    },\n",
    "    num_samples=5,\n",
    "    resources_per_trial={\"cpu\": 1},\n",
    ")\n",
    "```\n",
    "\n",
    "* It defines the search space for the hyperparameters.\n",
    "  * Both are sampled from a uniform distribution between -10 and 10.\n",
    "  * This means each number has an equal chance to be picked.\n",
    "* It sets `num_samples` to '5' in order to perform 5 trials of the full process (5 of our 1-step loop).\n",
    "* And it sets the available resources to be a single 'cpu' node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24416e6-cf19-4f07-b1ea-a4cf2a1c2ba2",
   "metadata": {},
   "source": [
    "Now that we've got a basic understanding of this experiment, let's use the cluster job client to execute it as a Ray Job.\n",
    "First, we'll need to initialise the client. The SDK will automatically gather the dashboard address and authenticate using the Ray Job Submission Client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6bf857-fe02-41df-9eef-02e68756ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cluster.job_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf73c2c-2325-4d24-ab53-0c308e422550",
   "metadata": {},
   "source": [
    "We can now declare the `submission_id` to the return value of `submit_jub()`. This function takes:\n",
    "\n",
    "* An `entrypoint` which is the command to pass as the Ray Job. In this case, a python execution of our script.\n",
    "* A `runtime _nv` in this case our local directory and the command to pip install our requirements.\n",
    "\n",
    "Once this cell has been executed, you should see some logging info from Ray and the `submission_id`.\n",
    "This will look similarly to: `raysubmit_sTV4SPtFup7JsxKH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42157c1f-ab41-40f9-a583-eaa6cb99aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id = client.submit_job(\n",
    "    entrypoint=\"python simple_mnist.py\",\n",
    "    runtime_env={\"working_dir\": \"./\",\"pip\": \"requirements.txt\"},\n",
    ")\n",
    "print(submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf69d77b-afc7-478b-b56f-cb5bcb6786b0",
   "metadata": {},
   "source": [
    "Now you can open the Ray Dashboard in order to observe the results of this experiment. When in the dashboard, click the \"jobs\" tab. Then find your Ray Job. It will look similar to the below image.\n",
    "\n",
    "![ray-job](images/ray-job.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390e872-9df2-45b5-9a06-7107b5ad5824",
   "metadata": {},
   "source": [
    "Click \"log\" on the far right of the screen and you can view the full logs of the Job. \n",
    "Early in the logs you should be able to see the pending trials. They will look akin to the below image.\n",
    "Within this, you can observe the x and y values for each trial and their status. These details are a result of the Ray Tune output.\n",
    "\n",
    "![ray-job](images/pending-trials.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89ac6f9-52ee-4c82-adde-e2b012518aa8",
   "metadata": {},
   "source": [
    "Further into the logs you'll be able to observe the results of each iteration. They will look similar to the below image, featuring details regarding the specific iteration including its duration and loss.\n",
    "\n",
    "![ray-job](images/iteration-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68618b-e5ee-4655-80bb-50306c0d8f1e",
   "metadata": {},
   "source": [
    "Finally, at the end of the log you should be able to observe the list of completed trials with accompanying data re loss, duration etc.\n",
    "\n",
    "![ray-job](images/trials-completed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f993a-beb4-40e9-89fd-902577ed12be",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
